{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scene_clustering\n",
    "This notebook contains inital code for clustering frames into shots, identifying the A/B/A/B pattern, and using the image classifier model to see if they're MCUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('site-packages') # manually put all packages/libraries into this folder\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "### For POC, designating a specific scene's worth of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose film and frames\n",
    "film = 'hustle'\n",
    "frame_choice = list(range(600, 1000)) # The Hustle, threshold 3100, +/- ~100 frames either side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5877 images in the folder\n",
      "Selected 400 of those frames\n"
     ]
    }
   ],
   "source": [
    "# establish folder for this film\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)\n",
    "\n",
    "print('There are', len(os.listdir(dialogue_folder)), 'images in the folder')\n",
    "print('Selected', len(frame_choice), 'of those frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model.summary()\n",
    "\n",
    "vgg16_feature_list = []\n",
    "\n",
    "\n",
    "for x in frame_choice:\n",
    "    img_path = dialogue_folder + '/' + film + '_frame'+ str(x) + '.jpg'\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "\n",
    "    vgg16_feature = model.predict(img_data)\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "    vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 32768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to NumPy array and verify shape\n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "vgg16_feature_list_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 39\n",
      "[ 5  5 29 29 29 23 23 23 23 23 23 23 23 23 23  5  5  5  5  5  5  5  0  0\n",
      "  0  0 20 20 20 20  8  8  8  8  8  8  8  8  8 11 11 11 28 28 28 11 11 11\n",
      "  2  2  2  2  2 25 25 17 17 31 31 31 31 31 31 26 26 26 14 14 14 14 26 26\n",
      " 26 26 26 35 31 31 31 31 14 14  2  2  2 17 17 17 17 10 10 10  4  4 30 30\n",
      " 30 30 10 10  4  4 17 17 17 25 25 25 25  2  2  2 35 17 17 17 17 17 17 17\n",
      " 35 35 35 35 30 30  4  4  4  4 30 30 30 30  4  4 26 26 26 26 26 14 14 14\n",
      " 14 14 30 30 30 35 35 35 35 30 30 30 35 30 10 10 10 12 12 12 27 27 27 27\n",
      " 27 22 22 22 22 22 22 22 22  8  8  8  8  8 27 27 27 27 27 27 27 27  0  0\n",
      "  0  0 27  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  9  9\n",
      "  9  9  9  9 33 33 33  9  9 33  9  9  9  9  9  9  9  9 33 33 33 33 33  9\n",
      "  9  9  9  9  9  9  9  9 21 21 21 21 21 21 21 21 21 21 21 33 33 33 33 33\n",
      " 16 16 18 33 33  9  9 33 33 33  9  9  9  9  9 18 18 18 18 18  0  0  0 33\n",
      " 33 33 16 16 16 16 16 16  9  9  9  9 33 33  9  9  9  9 33 33 33 33  9  9\n",
      "  9  9  9  9  9  9 19 19 19 19 19 19 19 19 19  0  0  0 12 12 12 12 37 37\n",
      " 37 37  0  0  0  0 13 13 13 13  0  0  0  0 34 34 34  0  0  0  0  0 38 38\n",
      " 38 38 38 38 38 32 32 32 32 32 36 36 36  6  6  6  6  6  6  3  3  3  7  7\n",
      "  7  7  7  7 24 24 24 24 15 15 15 15 15 15 15  0]\n"
     ]
    }
   ],
   "source": [
    "hac = AgglomerativeClustering(n_clusters = None, distance_threshold = 2900).fit(vgg16_feature_list_np)\n",
    "hac_labels = hac.labels_\n",
    "print('Number of clusters:', hac.n_clusters_)\n",
    "print(hac_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Model and Identify MCUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = models.load_model('saved_models/tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "for x in frame_choice:\n",
    "    image_list.append(img_to_array(load_img(dialogue_folder + '/' + film + '_frame'+ str(x) + '.jpg', target_size = (128, 128), color_mode = 'grayscale')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = np.array(image_list)\n",
    "y_pred = tuned_model.predict_classes(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model's predict_classes method creates a NumPy array of arrays; this converts it to a list of 0/1 integers\n",
    "y_pred_values = []\n",
    "for prediction in y_pred:\n",
    "    y_pred_values.append(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shot_ids(frame_choice, hac_labels):\n",
    "    shot_id = 0\n",
    "    shot_id_list = []\n",
    "    prev_frame = 1000\n",
    "\n",
    "    for frame_file, cluster in zip(frame_choice, hac_labels):\n",
    "        if cluster != prev_frame and prev_frame != 1000:\n",
    "            shot_id += 1\n",
    "        shot_id_list.append(shot_id)\n",
    "        # print(frame_file, '\\t', mcu_flag, '\\t', cluster, '\\t', prev_frame, '\\t', shot_id,'\\tend')\n",
    "        prev_frame = cluster\n",
    "    \n",
    "    return shot_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_id_list = get_shot_ids(frame_choice, hac_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_file</th>\n",
       "      <th>cluster</th>\n",
       "      <th>shot_id</th>\n",
       "      <th>mcu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>601</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>602</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>604</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>605</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>606</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_file  cluster  shot_id  mcu\n",
       "0         600        5        0    0\n",
       "1         601        5        0    0\n",
       "2         602       29        1    0\n",
       "3         603       29        1    0\n",
       "4         604       29        1    0\n",
       "5         605       23        2    0\n",
       "6         606       23        2    0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_df = pd.DataFrame(zip(frame_choice, hac_labels, shot_id_list, y_pred_values), columns=['frame_file', 'cluster', 'shot_id', 'mcu'])\n",
    "scene_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Pattern Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check all clusters for an A/B/A/B pattern of two clusters\n",
    "2. Check if the two clusters in each pattern are MCUs, and discard non-MCU patterns\n",
    "3. Get the earliest and latest frames with either speaker cluster, to determine the scene's anchor frames\n",
    "4. Get all clusters that lie in between the anchors, to determine the cutaway clusters\n",
    "5. Expand the scene in either direction by checking for adjacent cutaway clusters before the starting anchor and after the ending anchor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for A/B/A/B cluster pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 30], [30, 35], [0, 27], [9, 33]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_clust_1 = 1001\n",
    "prev_clust_1_list = []\n",
    "prev_clust_2 = 1002\n",
    "prev_clust_2_list = []\n",
    "prev_clust_3 = 1003\n",
    "prev_clust_3_list = []\n",
    "prev_shot_id = -1\n",
    "alternate_a_list = []\n",
    "alternate_b_list = []\n",
    "\n",
    "for frame_file, cluster, mcu_flag, shot_id in zip(frame_choice, hac_labels, y_pred_values, shot_id_list):\n",
    "    if cluster == prev_clust_2 and prev_clust_1 == prev_clust_3:\n",
    "        alternate_a_list.append(min(cluster, prev_clust_1))\n",
    "        alternate_b_list.append(max(cluster, prev_clust_1))\n",
    "\n",
    "    if shot_id != prev_shot_id:\n",
    "        prev_shot_id = shot_id\n",
    "        prev_clust_3 = prev_clust_2\n",
    "        prev_clust_2 = prev_clust_1\n",
    "        prev_clust_1 = cluster\n",
    "    prev_clust_1_list.append(prev_clust_1)\n",
    "    prev_clust_2_list.append(prev_clust_2)\n",
    "    prev_clust_3_list.append(prev_clust_3)\n",
    "    # print(frame_file, '\\t', mcu_flag, '\\t', cluster,'\\t', shot_id, '\\t', prev_shot_id, '\\t', prev_clust_1, '\\t', prev_clust_2, '\\t', prev_clust_3, '\\tend')\n",
    "\n",
    "alternating_pairs = []\n",
    "for a, b, in zip(alternate_a_list, alternate_b_list):\n",
    "    if [int(a), int(b)] not in alternating_pairs:\n",
    "        alternating_pairs.append([int(a), int(b)])\n",
    "alternating_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking both clusters if they're MCUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\t count\t mcu probability\n",
      "4 \t 10 \t 0.00%\n",
      "30 \t 17 \t 88.24%\n",
      "Fails MCU check\n",
      "\n",
      "30 \t 17 \t 88.24%\n",
      "35 \t 11 \t 81.82%\n",
      "Passes MCU check\n",
      "\n",
      "0 \t 30 \t 33.33%\n",
      "27 \t 14 \t 100.00%\n",
      "Fails MCU check\n",
      "\n",
      "9 \t 48 \t 97.92%\n",
      "33 \t 28 \t 100.00%\n",
      "Passes MCU check\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[30, 35], [9, 33]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_pairs = []\n",
    "print('cluster\\t', 'count\\t', 'mcu probability')\n",
    "for pair in alternating_pairs:\n",
    "    mean_a = scene_df.loc[scene_df['cluster'] == pair[0]]['mcu'].mean()\n",
    "    mean_b = scene_df.loc[scene_df['cluster'] == pair[1]]['mcu'].mean()\n",
    "    print(pair[0], '\\t', scene_df.loc[scene_df['cluster'] == pair[0]]['mcu'].count(), '\\t', '{0:.2f}%'.format(mean_a * 100))\n",
    "    print(pair[1], '\\t', scene_df.loc[scene_df['cluster'] == pair[1]]['mcu'].count(), '\\t', '{0:.2f}%'.format(mean_b * 100))\n",
    "    if mean_a > .5 and mean_b > .5:\n",
    "        print('Passes MCU check')\n",
    "        speaker_pairs.append(pair)\n",
    "    else:\n",
    "        print('Fails MCU check')\n",
    "    print()\n",
    "speaker_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing first and last frames of anchor clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 35]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = speaker_pairs[0]\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_file</th>\n",
       "      <th>cluster</th>\n",
       "      <th>shot_id</th>\n",
       "      <th>mcu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>675</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>694</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>695</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_file  cluster  shot_id  mcu\n",
       "75         675       35       17    0\n",
       "94         694       30       24    0\n",
       "95         695       30       24    1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_df.loc[(scene_df['cluster'] == pair[0]) | (scene_df['cluster'] == pair[1])].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_file</th>\n",
       "      <th>cluster</th>\n",
       "      <th>shot_id</th>\n",
       "      <th>mcu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>755</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>756</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>757</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frame_file  cluster  shot_id  mcu\n",
       "155         755       30       41    1\n",
       "156         756       35       42    1\n",
       "157         757       30       43    1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_df.loc[(scene_df['cluster'] == pair[0]) | (scene_df['cluster'] == pair[1])].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675 757\n"
     ]
    }
   ],
   "source": [
    "anchor_start = scene_df.loc[(scene_df['cluster'] == pair[0]) | (scene_df['cluster'] == pair[1])].frame_file.min()\n",
    "anchor_end = scene_df.loc[(scene_df['cluster'] == pair[0]) | (scene_df['cluster'] == pair[1])].frame_file.max()\n",
    "print(anchor_start, anchor_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding cutaways and expanding the scene's beginning and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 14,  2, 17, 10,  4, 25, 26])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutaways = scene_df.loc[(scene_df['frame_file'] > anchor_start) & (scene_df['frame_file'] < anchor_end)].cluster.unique()\n",
    "cutaways = cutaways[cutaways != pair[0]]\n",
    "cutaways = cutaways[cutaways != pair[1]]\n",
    "cutaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_start = anchor_start\n",
    "min_flag = 0\n",
    "\n",
    "while min_flag == 0:\n",
    "    try:\n",
    "        if int(scene_df.loc[scene_df['frame_file'] == (scene_start - 1)].cluster) in cutaways:\n",
    "            scene_start -= 1\n",
    "        else:\n",
    "            min_flag = 1\n",
    "    except TypeError: # error if hitting the beginning of the frame list\n",
    "        min_flag = 1\n",
    "scene_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_end = anchor_end\n",
    "max_flag = 0\n",
    "while max_flag == 0:\n",
    "    try:\n",
    "        if int(scene_df.loc[scene_df['frame_file'] == (scene_end + 1)].cluster) in cutaways:\n",
    "            scene_end += 1\n",
    "        else:\n",
    "            max_flag = 1\n",
    "    except TypeError: # error if hitting the end of the frame list\n",
    "        max_flag = 1\n",
    "scene_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 30], [30, 35], [0, 27], [9, 33]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternating_pairs = get_alternating_pairs(frame_choice, hac_labels, y_pred_values, shot_id_list)\n",
    "alternating_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\t count\t mcu probability\n",
      "4 \t 10 \t 0.00%\n",
      "30 \t 17 \t 88.24%\n",
      "Fails MCU check\n",
      "\n",
      "30 \t 17 \t 88.24%\n",
      "35 \t 11 \t 81.82%\n",
      "Passes MCU check\n",
      "\n",
      "0 \t 30 \t 33.33%\n",
      "27 \t 14 \t 100.00%\n",
      "Fails MCU check\n",
      "\n",
      "9 \t 48 \t 97.92%\n",
      "33 \t 28 \t 100.00%\n",
      "Passes MCU check\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[30, 35], [9, 33]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_pairs = mcu_check(alternating_pairs)\n",
    "speaker_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker A and B clusters: [30, 35]\n",
      "First, last frames of speakers A and B: 675 757\n",
      "Cutaway clusters: [31 14  2 17 10  4 25 26]\n",
      "Speaker A and B clusters: [9, 33]\n",
      "First, last frames of speakers A and B: 814 917\n",
      "Cutaway clusters: [21 16 18  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(648, 760), (814, 917)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes = expand_scenes(speaker_pairs, scene_df)\n",
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alternating_pairs(frame_choice, hac_labels, y_pred_values, shot_id_list):\n",
    "    \n",
    "    prev_clust_1 = 1001\n",
    "    prev_clust_1_list = []\n",
    "    prev_clust_2 = 1002\n",
    "    prev_clust_2_list = []\n",
    "    prev_clust_3 = 1003\n",
    "    prev_clust_3_list = []\n",
    "    prev_shot_id = -1\n",
    "    alternate_a_list = []\n",
    "    alternate_b_list = []\n",
    "\n",
    "    for frame_file, cluster, mcu_flag, shot_id in zip(frame_choice, hac_labels, y_pred_values, shot_id_list):\n",
    "        if cluster == prev_clust_2 and prev_clust_1 == prev_clust_3:\n",
    "            alternate_a_list.append(min(cluster, prev_clust_1))\n",
    "            alternate_b_list.append(max(cluster, prev_clust_1))\n",
    "\n",
    "        if shot_id != prev_shot_id:\n",
    "            prev_shot_id = shot_id\n",
    "            prev_clust_3 = prev_clust_2\n",
    "            prev_clust_2 = prev_clust_1\n",
    "            prev_clust_1 = cluster\n",
    "        prev_clust_1_list.append(prev_clust_1)\n",
    "        prev_clust_2_list.append(prev_clust_2)\n",
    "        prev_clust_3_list.append(prev_clust_3)\n",
    "        # print(frame_file, '\\t', mcu_flag, '\\t', cluster,'\\t', shot_id, '\\t', prev_shot_id, '\\t', prev_clust_1, '\\t', prev_clust_2, '\\t', prev_clust_3, '\\tend')\n",
    "\n",
    "    alternating_pairs = []\n",
    "    for a, b, in zip(alternate_a_list, alternate_b_list):\n",
    "        if [int(a), int(b)] not in alternating_pairs:\n",
    "            alternating_pairs.append([int(a), int(b)])\n",
    "    \n",
    "    return alternating_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcu_check(alternating_pairs):\n",
    "    speaker_pairs = []\n",
    "    print('cluster\\t', 'count\\t', 'mcu probability')\n",
    "    \n",
    "    for pair in alternating_pairs:\n",
    "        mean_a = scene_df.loc[scene_df['cluster'] == pair[0]]['mcu'].mean()\n",
    "        mean_b = scene_df.loc[scene_df['cluster'] == pair[1]]['mcu'].mean()\n",
    "        print(pair[0], '\\t', scene_df.loc[scene_df['cluster'] == pair[0]]['mcu'].count(), '\\t', '{0:.2f}%'.format(mean_a * 100))\n",
    "        print(pair[1], '\\t', scene_df.loc[scene_df['cluster'] == pair[1]]['mcu'].count(), '\\t', '{0:.2f}%'.format(mean_b * 100))\n",
    "        if mean_a > .5 and mean_b > .5:\n",
    "            print('Passes MCU check')\n",
    "            speaker_pairs.append(pair)\n",
    "        else:\n",
    "            print('Fails MCU check')\n",
    "        print()\n",
    "    \n",
    "    return speaker_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_scenes(speaker_pairs, scene_df):\n",
    "    scenes = []\n",
    "\n",
    "    for pair in speaker_pairs:\n",
    "        anchor_start = scene_df.loc[(scene_df['cluster'] == pair[0]) | (scene_df['cluster'] == pair[1])].frame_file.min()\n",
    "        anchor_end = scene_df.loc[(scene_df['cluster'] == pair[0]) | (scene_df['cluster'] == pair[1])].frame_file.max()\n",
    "        cutaways = scene_df.loc[(scene_df['frame_file'] > anchor_start) & (scene_df['frame_file'] < anchor_end)].cluster.unique()\n",
    "        cutaways = cutaways[cutaways != pair[0]]\n",
    "        cutaways = cutaways[cutaways != pair[1]]\n",
    "        print('Speaker A and B clusters:', pair)\n",
    "        print('First, last frames of speakers A and B:', anchor_start, anchor_end)\n",
    "        print('Cutaway clusters:', cutaways)\n",
    "\n",
    "        scene_start = anchor_start\n",
    "        min_flag = 0\n",
    "\n",
    "        while min_flag == 0:\n",
    "            try:\n",
    "                if int(scene_df.loc[scene_df['frame_file'] == (scene_start - 1)].cluster) in cutaways:\n",
    "                    scene_start -= 1\n",
    "                else:\n",
    "                    min_flag = 1\n",
    "            except TypeError: # error if hitting the beginning of the frame list\n",
    "                min_flag = 1\n",
    "\n",
    "        scene_end = anchor_end\n",
    "        max_flag = 0\n",
    "        while max_flag == 0:\n",
    "            try:\n",
    "                if int(scene_df.loc[scene_df['frame_file'] == (scene_end + 1)].cluster) in cutaways:\n",
    "                    scene_end += 1\n",
    "                else:\n",
    "                    max_flag = 1\n",
    "            except TypeError: # error if hitting the end of the frame list\n",
    "                max_flag = 1\n",
    "\n",
    "        scenes.append((scene_start, scene_end))\n",
    "            \n",
    "    return scenes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
