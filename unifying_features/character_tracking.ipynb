{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Tracking\n",
    "As part of our overall effort to follow the events of the film, we'll want to track characters throughout the movie. We do this by creating dictionaries which will primarily recognize characters by face - more specifically, their facial encoding clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../data_serialization')\n",
    "from serialization_preprocessing_io import *\n",
    "from time_reference_io import *\n",
    "from scene_identification_io import *\n",
    "from collections import Counter\n",
    "from character_identification_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'plus_one_2019'\n",
    "srt_df, subtitle_df, sentence_df, vision_df, face_df = read_pickle(film)\n",
    "scene_dictionaries = generate_scenes(vision_df, face_df, substantial_minimum=4, anchor_search=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a dictionary of scenes. Recall that each scene was found because there was a character in the left anchor shots, and another character in the right anchor shots. Because of the inconsistencies in face clustering, there may be multiple face clusters associated with a character.\n",
    "\n",
    "So in a single scene, we're pretty confident that every face in a left anchor shot is the same character, and every face in a right anchor shot is the same character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scene_id': 1,\n",
       " 'first_frame': 483,\n",
       " 'last_frame': 527,\n",
       " 'scene_duration': 45,\n",
       " 'left_anchor_shot_cluster': 179,\n",
       " 'left_anchor_face_cluster': 3.0,\n",
       " 'matching_left_face_clusters': [11.0],\n",
       " 'right_anchor_shot_cluster': 86,\n",
       " 'right_anchor_face_cluster': 15.0,\n",
       " 'matching_right_face_clusters': [5.0],\n",
       " 'cutaway_shot_clusters': [39]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_dictionaries[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the first scene, we know that the left anchor character can be represented by two separate face clusters: 3 and 11. The right anchor character can be represented by two face clusters: 15 and 5. We'll attempt to use this logic and join these clusters together in all the film's scenes.\n",
    "### Figuring out each characters' different face encodings\n",
    "We'll iterate through each scene and do the same thing: look at the faces on the left, and look at the faces on the right. We'll assume that all the left faces are a character, and all the right faces are another character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_face_cluster_lists = []\n",
    "\n",
    "x = 1\n",
    "\n",
    "while x <= len(scene_dictionaries):\n",
    "    scene_left_list = []\n",
    "\n",
    "    scene_left_list.append(scene_dictionaries[x]['left_anchor_face_cluster'])\n",
    "\n",
    "    for matching_left_face in scene_dictionaries[x]['matching_left_face_clusters']:\n",
    "        scene_left_list.append(matching_left_face)\n",
    "\n",
    "    scene_right_list = []\n",
    "\n",
    "    scene_right_list.append(scene_dictionaries[x]['right_anchor_face_cluster'])\n",
    "\n",
    "    for matching_right_face in scene_dictionaries[x]['matching_right_face_clusters']:\n",
    "        scene_right_list.append(matching_right_face)\n",
    "\n",
    "    anchor_face_cluster_lists.append(scene_left_list)\n",
    "    anchor_face_cluster_lists.append(scene_right_list)\n",
    "\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each of the 18 scenes, we create two lists (one for the left, and one for the right). We end up with 36 lists, each linking some face clusters together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(scene_dictionaries))\n",
    "print(len(anchor_face_cluster_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.0, 11.0],\n",
       " [15.0, 5.0],\n",
       " [8.0, 2.0],\n",
       " [11.0, 17.0],\n",
       " [2.0, 8.0],\n",
       " [3.0, 13.0, 0.0, 11.0],\n",
       " [2.0, 8.0],\n",
       " [11.0, 3.0],\n",
       " [2.0, 8.0],\n",
       " [3.0, 11.0],\n",
       " [3.0],\n",
       " [1.0],\n",
       " [28.0],\n",
       " [10.0, 7.0, 8.0],\n",
       " [4.0],\n",
       " [3.0, 17.0],\n",
       " [3.0],\n",
       " [26.0],\n",
       " [2.0],\n",
       " [17.0, 11.0],\n",
       " [2.0, 8.0],\n",
       " [11.0, 17.0, 3.0],\n",
       " [22.0, 8.0],\n",
       " [8.0],\n",
       " [22.0, 2.0],\n",
       " [17.0, 3.0, 11.0],\n",
       " [22.0],\n",
       " [17.0],\n",
       " [17.0, 0.0, 13.0, 31.0],\n",
       " [14.0],\n",
       " [31.0],\n",
       " [2.0, 8.0],\n",
       " [31.0, 11.0, 3.0],\n",
       " [2.0, 8.0],\n",
       " [10.0, 2.0],\n",
       " [11.0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_face_cluster_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 11.0]\n",
      "[11.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "print(anchor_face_cluster_lists[0])\n",
    "print(anchor_face_cluster_lists[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to count the clusters that show up most often, and we'll use these as the basis of matching face encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_anchor_list = []\n",
    "for anchor_list in anchor_face_cluster_lists:\n",
    "    for anchor in anchor_list:\n",
    "        flattened_anchor_list.append(anchor)\n",
    "\n",
    "anchor_character_counter = Counter(flattened_anchor_list)\n",
    "most_common_anchors = []\n",
    "\n",
    "common_count = 5\n",
    "for anchor in anchor_character_counter.most_common(common_count):\n",
    "    most_common_anchors.append(anchor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 11.0, 8.0, 2.0, 17.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these five anchor faces, we'll see which other faces match them by looping through each scene they're in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 3.0, 11.0, 13.0, 17.0, 31.0],\n",
       " [0.0, 3.0, 11.0, 13.0, 17.0, 31.0],\n",
       " [2.0, 7.0, 8.0, 10.0, 22.0],\n",
       " [2.0, 7.0, 8.0, 10.0, 22.0],\n",
       " [0.0, 3.0, 11.0, 13.0, 17.0, 31.0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_cluster_list = []\n",
    "\n",
    "for character in most_common_anchors:\n",
    "    matching_clusters = [character]\n",
    "    search_clusters = []\n",
    "    search_continues = 1\n",
    "\n",
    "    # search face clusters of all scenes to find matching clusters, then repeat search until no more found\n",
    "    while search_continues == 1:\n",
    "        if search_clusters:\n",
    "            matching_clusters = search_clusters.copy()\n",
    "        for anchor_face_clusters in anchor_face_cluster_lists:\n",
    "            for matching_cluster in matching_clusters:\n",
    "                if matching_cluster in anchor_face_clusters:\n",
    "                    for anchor_face in anchor_face_clusters:\n",
    "                        search_clusters.append(anchor_face)\n",
    "        search_clusters = list(set(search_clusters))\n",
    "\n",
    "        if sorted(matching_clusters) == sorted(search_clusters):\n",
    "            search_continues = 0\n",
    "            character_cluster_list.append(sorted(matching_clusters))\n",
    "\n",
    "character_cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 3.0, 11.0, 13.0, 17.0, 31.0], [2.0, 7.0, 8.0, 10.0, 22.0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_character_clusters = []\n",
    "for character_clusters in character_cluster_list:\n",
    "    if character_clusters not in unique_character_clusters:\n",
    "        unique_character_clusters.append(character_clusters)\n",
    "\n",
    "unique_character_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we've just discovered all the face encodings matching the film's two main characters. This functionality is found in a function `generate_character_clusters()` in `character_identification_io`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Dictionaries\n",
    "With the ability to group face encodings together into characters, we can search all scenes for these face encodings. For each of the two characters, we assign a character_id, list the clusters, and in which scenes they're found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'character_id': 1,\n",
       "  'face_clusters': [0.0, 3.0, 11.0, 13.0, 17.0, 31.0],\n",
       "  'scenes_present': [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18]},\n",
       " {'character_id': 2,\n",
       "  'face_clusters': [2.0, 7.0, 8.0, 10.0, 22.0],\n",
       "  'scenes_present': [2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_clusters = generate_character_clusters(scene_dictionaries)\n",
    "character_dictionary_list = []\n",
    "\n",
    "y = 1\n",
    "for single_character_face_clusters in character_clusters:\n",
    "\n",
    "    character_scenes = []\n",
    "\n",
    "    x = 1\n",
    "    while x <= len(scene_dictionaries):\n",
    "        for cluster in single_character_face_clusters:\n",
    "            if cluster == scene_dictionaries[x]['left_anchor_face_cluster'] or cluster in scene_dictionaries[x][\n",
    "                'matching_left_face_clusters'] or cluster == scene_dictionaries[x][\n",
    "                'right_anchor_face_cluster'] or cluster in scene_dictionaries[x]['matching_right_face_clusters']:\n",
    "                character_scenes.append(x)\n",
    "        x += 1\n",
    "\n",
    "    character_scenes = sorted(list(set(character_scenes)))\n",
    "\n",
    "    character_dict = {'character_id': y,\n",
    "                      'face_clusters': single_character_face_clusters,\n",
    "                      'scenes_present': character_scenes}\n",
    "\n",
    "    character_dictionary_list.append(character_dict)\n",
    "    y += 1\n",
    "\n",
    "character_dictionary_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we flatten the list into an actual dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'character_id': 1,\n",
       "  'face_clusters': [0.0, 3.0, 11.0, 13.0, 17.0, 31.0],\n",
       "  'scenes_present': [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18]},\n",
       " 2: {'character_id': 2,\n",
       "  'face_clusters': [2.0, 7.0, 8.0, 10.0, 22.0],\n",
       "  'scenes_present': [2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_dictionaries = {}\n",
    "z = 1\n",
    "\n",
    "for character_dict in character_dictionary_list:\n",
    "    character_dictionaries[z] = character_dict\n",
    "    z += 1\n",
    "\n",
    "character_dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This logic is wrapped in the function `generate_characters()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
