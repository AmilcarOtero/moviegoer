{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conversation_mood\n",
    "One goal of *Moviegoer* is calculating and comparing the emotional aspects of scenes' conversations. We can quantify a conversation's mood/vibe in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subtitle_dataframes_io import *\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/plus_one_2019.srt')\n",
    "subtitle_df = generate_base_subtitle_df(subs)\n",
    "subtitle_df = generate_subtitle_features(subtitle_df)\n",
    "subtitle_df['cleaned_text'] = subtitle_df['concat_sep_text'].map(clean_line)\n",
    "sentences = partition_sentences(remove_blanks(subtitle_df['cleaned_text'].tolist()), nlp)\n",
    "subtitle_indices = tie_sentence_subtitle_indices(sentences, subtitle_df)\n",
    "sentence_df = pd.DataFrame(list(zip(sentences, subtitle_indices)), columns=['sentence', 'subtitle_indices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profanity\n",
    "The easiest way to measure drama is by identifying and counting profanity. We can define a list of profanities for which to search. Then we'll break the sentence into lemma, so that we can find derivations in the vein of \"hecked\", \"heckin'\", \"hecking\", \"hecky\", etc.\n",
    "\n",
    "This is defined as a function *profanity()* in *phrases_io.py* and is used to find profanity at the scene- and film-level. These can be compared to find scenes with higher profanity than the film average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He's fucking talking about babies.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sentence_df.iloc[814].sentence\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_doc = nlp(sentence)\n",
    "profanity_count = 0\n",
    "\n",
    "profanities = ['fuck', 'fucking', 'fuckin', 'fucked', 'shit', 'shitty', 'bullshit', 'ass', 'dumbass', 'bitch', 'asshole', 'tit', 'cunt', 'goddamn', 'damn', 'dammit', 'cock', 'cocksucker', 'dick']\n",
    "for word in sent_doc:\n",
    "    if word.lemma_.lower() in profanities:\n",
    "        profanity_count += 1\n",
    "\n",
    "profanity_count\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
