{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subtitle_analysis\n",
    "We can extract a film's English-language subtitle track to get the ground-truth dialogue. We can glean clues about a scene's location, characters, and context. While we're not yet ready to use subtitles to analyze the film's entire plot, we can start small and see what localized information we can learn.\n",
    "\n",
    "We'll be using the `pysrt` library to parse .srt subtitle files and the `spaCy` library for NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from subtitle_cleaning_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/booksmart.srt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each two-line dialogue in a subtitle file is explicitly numbered, starting at 1, there's an off-by-one discrepency with the list object (starting at 0). We can offset the list by just duplicating the first subtitle item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle files (.srt) are explicitly numbered, and start at 1\n",
    "subs.insert(0, subs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each SubRipItem contains the subtitle text as well as the start and end time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a deep breath.\n",
      "00:00:09,177\n",
      "00:00:11,011\n"
     ]
    }
   ],
   "source": [
    "print(subs[4].text)\n",
    "print(subs[4].start)\n",
    "print(subs[4].end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "### Initial Analysis\n",
    "We can use the `spaCy` library for natural-language processing (NLP). We'll eventually look at all of the lines as a whole, but for now, we'll see what we can do for a single line of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No one in this entire school\\nknows me at all.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[1883].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = subs[1883].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can separate the line into individual tokens. We can also remove all the stop words or see parts of speech. Note that the line break causes some weird results, but we'll deal with this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[No, one, in, this, entire, school, , knows, me, at, all, .]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[entire, school, , knows, .]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_stop = []\n",
    "for word in doc:\n",
    "    if word.is_stop == False:\n",
    "        non_stop.append(word)\n",
    "\n",
    "non_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DET\n",
      "one NOUN\n",
      "in ADP\n",
      "this DET\n",
      "entire ADJ\n",
      "school NOUN\n",
      "\n",
      " SPACE\n",
      "knows VERB\n",
      "me PRON\n",
      "at ADV\n",
      "all ADV\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "### Character Names \n",
    "It's easy to conduct Named Entity Recogntion (NER) with spaCy. The most prominent use of NER would be to discover character names. In film, the audience usually learns character names when their names are spoken aloud. We can get a count of all spoken names and see if it lines up with the actual character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dialogue = []\n",
    "for sub_object in subs:\n",
    "    all_dialogue.append(sub_object.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp('\\n'.join(all_dialogue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON':\n",
    "        people.append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amy', 44),\n",
       " ('AMY', 24),\n",
       " ('Molly', 16),\n",
       " ('Nick', 12),\n",
       " ('Ryan', 12),\n",
       " ('Malala', 8),\n",
       " ('Fine', 7),\n",
       " ('Jesus Christ', 6),\n",
       " ('Alan', 6),\n",
       " ('Jesus', 6)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Six of the ten most common names are actual character names. But we can improve on this: we know \"Jesus\" is usually used as an exclamation, and the all-caps AMY is most likely a subtitle indication that the character of Amy is speaking lines (as opposed to someone saying \"Amy\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitle Cleanup\n",
    "Subtitle files are already formatted very neatly. It shouldn't be too hard to clean and shape this data into a format we can use.\n",
    "### Individual Line Cleaning\n",
    "Subtitle text spans either one or two lines. Text that span two lines may contain dialogue from either one character, or two separate characters.\n",
    "\n",
    "This is a one-liner, which is just one character speaking.\n",
    "\n",
    "`29\n",
    "00:01:19,747 --> 00:01:21,081\n",
    "I missed you.`\n",
    "\n",
    "Here, a single character spoke enough dialogue to span two lines.\n",
    "\n",
    "`69\n",
    "00:02:43,331 --> 00:02:45,248\n",
    "I mean, he's you know,\n",
    "he's the vice president.`\n",
    "\n",
    "And this is a two-liner that has two characters speaking. (Molly's name is printed because she's speaking from offscreen.) It starts with a dash on each line.\n",
    "\n",
    "`30\n",
    "00:01:21,165 --> 00:01:22,832\n",
    "-I missed you so much.\n",
    "-MOLLY: Been one night.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I missed you.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[29].text # one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I mean, he's you know,\\nhe's the vice president.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[69].text # two-liner from one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-I missed you so much.\\n-MOLLY: Been one night.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[30].text # two-liner spoken by two characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For best results during NLP processing, we'll want to separate the two line, two character text into two separate lines. We'll also want to combine the two line, one character text into a single line. The key to this is searching for the newline escape sequence.\n",
    "\n",
    "If there's no newline escape, then it's a one-liner.  If it has a newline sequence and both the top and bottom lines start with a dash, it's a two line, two character text and should be broken into two separate lines (and discarding both dashes). And if it has a newline sequence but without the dashes, it's a single character speaking across two lines, and we'll concatenate the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(text):\n",
    "    newline = text.find('\\n')\n",
    "    if newline == -1:                     # one-liner\n",
    "        return text, 0\n",
    "    elif text[0] == '-' and text[newline + 1] == '-': # two-liner spoken by two characters\n",
    "        top_line = text[1:newline]\n",
    "        bottom_line = text[newline + 2:]\n",
    "        return top_line.lstrip(), bottom_line.lstrip()\n",
    "    else:                                        # two-liner from one character\n",
    "        concat_line = text[:newline] + ' ' + text[newline + 1:]\n",
    "        return concat_line, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I missed you.', 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_line(subs[29].text) # one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I missed you so much.', 'MOLLY: Been one night.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_line(subs[30].text) # two-liner spoken by two characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I mean, he's you know, he's the vice president.\", 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_line(subs[69].text) # two-liner from one character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we can separate or combine each line appropriately. These can be collected into a single list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dialogue = []\n",
    "for sub_object in subs:\n",
    "    text = sub_object.text\n",
    "    line_a, line_b = clean_line(text)\n",
    "    all_dialogue.append(line_a)\n",
    "    if line_b != 0:\n",
    "        all_dialogue.append(line_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['True.',\n",
       " 'PRINCIPAL BROWN: I hope',\n",
       " 'I never have to see any of you',\n",
       " 'ever again, okay.',\n",
       " \"That's it. Signin' off.\",\n",
       " 'Go, Crocketts!',\n",
       " '(mic feedback)',\n",
       " 'Boom.',\n",
       " 'MOLLY: Principal Brown?',\n",
       " '(groaning)']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dialogue[57:67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2374\n",
      "2700\n"
     ]
    }
   ],
   "source": [
    "print(len(subs)) # number of subtitle objects\n",
    "print(len(all_dialogue)) # number of cleaned lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Specific Cases\n",
    "Though the majority of subtitle text is spoken dialogue, there are non-dialogue lines which clarify non-word sounds like laughter or intentionally inaudible audio. They may also contain song lyrics or denote an off-screen speaker. All of these specific cases have distinct formatting.\n",
    "\n",
    "- parenthetical, entire-line: may describe laughter, sighing, indistinct muttering\n",
    "- music, entire-line: may transcribe song lyrics sung by characters, or non-diegetic score music\n",
    "- laughter, partial- or entire-line: describes laughter as the entire line, or perhaps a quick chuckle before speaking dialogue. The list of strings that might describe laughter, like '(laughing)' or '(chuckles)' is small enough where we can hard-code them\n",
    "- offscreen character: clarification on the speaker, if coming from an offscreen character — the hearing-impaired need this clue because they aren't able to recognize voices\n",
    "- italics, entire-line: may indicate narration, voice-over, or an off-screen voice speaking on the phone\n",
    "\n",
    "These will all be available as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mic feedback)\n",
      "(groaning)\n"
     ]
    }
   ],
   "source": [
    "for line in all_dialogue[57:67]:\n",
    "    if line[:1] == '(' and line[-1:] == ')':    # parenthetical, entire-line\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "♪ I don't wanna stress you out ♪\n",
      "♪ I just wanna tell you the truth ♪\n",
      "♪ Motherfuckers try to tear us apart ♪\n",
      "♪ But we're electric linked ♪\n"
     ]
    }
   ],
   "source": [
    "for line in all_dialogue[35:45]:\n",
    "    if line[:1] == '♪' and line[-1:] == '♪':   # music, entire-line\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(laughing)\n",
      "every single night! (laughs)\n"
     ]
    }
   ],
   "source": [
    "laugh_strings = ['(laughing)', '(laughs)', '(chuckles)']      # laughter\n",
    "for line in all_dialogue[650:700]:\n",
    "    for laugh in laugh_strings:\n",
    "        if laugh in line:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMY\n",
      "MOLLY\n",
      "MOLLY\n",
      "BOY\n"
     ]
    }
   ],
   "source": [
    "for line in all_dialogue[30:50]:\n",
    "    colon_find = line.find(':')            # off-screen speaker\n",
    "    if line[0:colon_find].isupper():\n",
    "        print(line[0:colon_find])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i>I decided to spend the month of August</i>\n",
      "<i>in the spa town of Nebelsbad below the Alpine Sudetenwaltz,</i>\n",
      "<i>and had taken up rooms in the Grand Budapest,</i>\n",
      "<i>a picturesque, elaborate, and once widely celebrated establishment.</i>\n"
     ]
    }
   ],
   "source": [
    "subs = pysrt.open('../subtitles/the_grand_budapest_hotel.srt') # switching subtitles to The Grand Budapest Hotel\n",
    "subs.insert(0, subs[0])\n",
    "all_dialogue = []\n",
    "for sub_object in subs:\n",
    "    text = sub_object.text\n",
    "    line_a, line_b = clean_line(text)\n",
    "    all_dialogue.append(line_a)\n",
    "    if line_b != 0:\n",
    "        all_dialogue.append(line_b)\n",
    "        \n",
    "for line in all_dialogue[25:29]:                # italics\n",
    "    if line[:3] == '<i>' and line[-4:] == '</i>':\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Text and Populating DataFrame\n",
    "We've turned the above functionality into various functions found in `subtitle_cleaning_io.py`. Each of the functions returns cleaned text, which will be fed as NLP input, as well as a flag or other piece of information for the DataFrame. For example, the `italic_clean()` function returns a flag if the entire line is in italics. The `speaker_clean()` function will return the speaker name, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/booksmart.srt')\n",
    "subs.insert(0, subs[0])\n",
    "single_lines = generate_single_lines(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "italic_flags = []\n",
    "music_flags = []\n",
    "laugh_flags = []\n",
    "speakers = []\n",
    "parenthetical_flags = []\n",
    "\n",
    "cleaned_lines = []\n",
    "\n",
    "for line in single_lines:\n",
    "    entire_line_italic, line = italic_clean(line)\n",
    "    italic_flags.append(entire_line_italic)\n",
    "    \n",
    "    entire_line_music, line = music_clean(line)\n",
    "    music_flags.append(entire_line_music)\n",
    "    \n",
    "    laugh_found, line = laugh_clean(line)\n",
    "    laugh_flags.append(laugh_found)\n",
    "    \n",
    "    speaker, line = speaker_clean(line)\n",
    "    speakers.append(speaker)\n",
    "    \n",
    "    entire_line_parenthetical, line = parenthetical_clean(line)\n",
    "    parenthetical_flags.append(entire_line_parenthetical)\n",
    "    \n",
    "    cleaned_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't call her that.\n",
      "Everybody calls her that.\n",
      "She gave roadside assistance\n",
      "to three senior guys last year.\n",
      "You hear them getting degrading Nicknames?\n"
     ]
    }
   ],
   "source": [
    "for line in cleaned_lines[100:105]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only do we have a list of cleaned, NLP-ready dialogue, but we also have various lists that we'll use for the DataFrame. Here are two examples: these lists indiate where a line contains laughter, or a specific offscreen speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laugh_flags[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'AMY',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'MISS FINE',\n",
       " 'none',\n",
       " 'none']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of properly separated or concatenated, clean lines of dialogue. We still have some blank lines, which were generated when we were cleaning an entire line — the above blank is from a parenthetical description \"(mic feedback)\".\n",
    "\n",
    "We can easily remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I never have to see any of you\n",
      "ever again, okay.\n",
      "That's it. Signin' off.\n",
      "Go, Crocketts!\n",
      "\n",
      "Boom.\n"
     ]
    }
   ],
   "source": [
    "for line in cleaned_lines[59:65]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_removed = []\n",
    "\n",
    "for line in cleaned_lines:\n",
    "    if line:\n",
    "        blanks_removed.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n",
      "2270\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_lines))  # all cleaned lines\n",
    "print(len(blanks_removed)) # blanks removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `blanks_removed` list is ready to be put through various NLP analyses. We can also start populating the DataFrame by combining all the lists. These will take place in the next notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
