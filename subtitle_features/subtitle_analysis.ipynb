{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subtitle_analysis\n",
    "We can extract a film's English-language subtitle track to get the ground-truth dialogue. We can glean clues about a scene's location, characters, and context. While we're not yet ready to use subtitles to analyze the film's entire plot, we can start small and see what localized information we can learn.\n",
    "\n",
    "We'll be using the `pysrt` library to parse .srt subtitle files and the `spaCy` library for NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/booksmart.srt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each two-line dialogue in a subtitle file is explicitly numbered, starting at 1, there's an off-by-one discrepency with the list object (starting at 0). We can offset the list by just duplicating the first subtitle item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle files (.srt) are explicitly numbered, and start at 1\n",
    "subs.insert(0, subs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each SubRipItem contains the subtitle text as well as the start and end time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a deep breath.\n",
      "00:00:09,177\n",
      "00:00:11,011\n"
     ]
    }
   ],
   "source": [
    "print(subs[4].text)\n",
    "print(subs[4].start)\n",
    "print(subs[4].end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "### Initial Analysis\n",
    "We can use the `spaCy` library for natural-language processing (NLP). We'll eventually look at all of the lines as a whole, but for now, we'll see what we can do for a single line of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No one in this entire school\\nknows me at all.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[1883].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = subs[1883].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can separate the line into individual tokens. We can also remove all the stop words or see parts of speech. Note that the line break causes some weird results, but we'll deal with this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[No, one, in, this, entire, school, , knows, me, at, all, .]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[entire, school, , knows, .]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_stop = []\n",
    "for word in doc:\n",
    "    if word.is_stop == False:\n",
    "        non_stop.append(word)\n",
    "\n",
    "non_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DET\n",
      "one NOUN\n",
      "in ADP\n",
      "this DET\n",
      "entire ADJ\n",
      "school NOUN\n",
      "\n",
      " SPACE\n",
      "knows VERB\n",
      "me PRON\n",
      "at ADV\n",
      "all ADV\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
