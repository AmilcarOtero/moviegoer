{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subtitle_analysis\n",
    "We can extract a film's English-language subtitle track to get the ground-truth dialogue. We can glean clues about a scene's location, characters, and context. While we're not yet ready to use subtitles to analyze the film's entire plot, we can start small and see what localized information we can learn.\n",
    "\n",
    "We'll be using the `pysrt` library to parse .srt subtitle files and the `spaCy` library for NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/booksmart.srt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each two-line dialogue in a subtitle file is explicitly numbered, starting at 1, there's an off-by-one discrepency with the list object (starting at 0). We can offset the list by just duplicating the first subtitle item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle files (.srt) are explicitly numbered, and start at 1\n",
    "subs.insert(0, subs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each SubRipItem contains the subtitle text as well as the start and end time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a deep breath.\n",
      "00:00:09,177\n",
      "00:00:11,011\n"
     ]
    }
   ],
   "source": [
    "print(subs[4].text)\n",
    "print(subs[4].start)\n",
    "print(subs[4].end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "### Initial Analysis\n",
    "We can use the `spaCy` library for natural-language processing (NLP). We'll eventually look at all of the lines as a whole, but for now, we'll see what we can do for a single line of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No one in this entire school\\nknows me at all.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[1883].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = subs[1883].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can separate the line into individual tokens. We can also remove all the stop words or see parts of speech. Note that the line break causes some weird results, but we'll deal with this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[No, one, in, this, entire, school, , knows, me, at, all, .]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[entire, school, , knows, .]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_stop = []\n",
    "for word in doc:\n",
    "    if word.is_stop == False:\n",
    "        non_stop.append(word)\n",
    "\n",
    "non_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DET\n",
      "one NOUN\n",
      "in ADP\n",
      "this DET\n",
      "entire ADJ\n",
      "school NOUN\n",
      "\n",
      " SPACE\n",
      "knows VERB\n",
      "me PRON\n",
      "at ADV\n",
      "all ADV\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "### Character Names \n",
    "It's easy to conduct Named Entity Recogntion (NER) with spaCy. The most prominent use of NER would be to discover character names. In film, the audience usually learns character names when their names are spoken aloud. We can get a count of all spoken names and see if it lines up with the actual character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dialogue = []\n",
    "for sub_object in subs:\n",
    "    all_dialogue.append(sub_object.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp('\\n'.join(all_dialogue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON':\n",
    "        people.append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amy', 44),\n",
       " ('AMY', 24),\n",
       " ('Molly', 16),\n",
       " ('Nick', 12),\n",
       " ('Ryan', 12),\n",
       " ('Malala', 8),\n",
       " ('Fine', 7),\n",
       " ('Jesus Christ', 6),\n",
       " ('Alan', 6),\n",
       " ('Jesus', 6)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Six of the ten most common names are actual character names. But we can improve on this: we know \"Jesus\" is usually used as an exclamation, and the all-caps AMY is most likely a subtitle indication that the character of Amy is speaking lines (as opposed to someone saying \"Amy\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitle Cleanup\n",
    "Subtitle files are already formatted very neatly. It shouldn't be too hard to clean and shape this data into a format we can use.\n",
    "### Individual Line Parsing\n",
    "Subtitle text spans either one or two lines. Text that span two lines may contain dialogue from either one character, or two separate characters.\n",
    "\n",
    "This is a one-liner, which is just one character speaking.\n",
    "\n",
    "`29\n",
    "00:01:19,747 --> 00:01:21,081\n",
    "I missed you.`\n",
    "\n",
    "Here, a single character spoke enough dialogue to span two lines.\n",
    "\n",
    "`69\n",
    "00:02:43,331 --> 00:02:45,248\n",
    "I mean, he's you know,\n",
    "he's the vice president.`\n",
    "\n",
    "And this is a two-liner that has two characters speaking. (Molly's name is printed because she's speaking from offscreen.) It starts with a dash on each line.\n",
    "\n",
    "`30\n",
    "00:01:21,165 --> 00:01:22,832\n",
    "-I missed you so much.\n",
    "-MOLLY: Been one night.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I missed you.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[29].text # one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I mean, he's you know,\\nhe's the vice president.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[69].text # two-liner from one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-I missed you so much.\\n-MOLLY: Been one night.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[30].text # two-liner spoken by two characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For best results during NLP processing, we'll want to separate the two line, two character text into two separate lines. We'll also want to combine the two line, one character text into a single line. The key to this is searching for the newline escape sequence.\n",
    "\n",
    "If there's no newline escape, then it's a one-liner.  If it has a newline sequence and both the top and bottom lines start with a dash, it's a two line, two character text and should be broken into two separate lines (and discarding both dashes). And if it has a newline sequence but without the dashes, it's a single character speaking across two lines, and we'll concatenate the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(text):\n",
    "    newline = text.find('\\n')\n",
    "    if newline == -1:                     # one-liner\n",
    "        return text, 0\n",
    "    elif text[0] == '-' and text[newline + 1] == '-': # two-liner spoken by two characters\n",
    "        top_line = text[1:newline]\n",
    "        bottom_line = text[newline + 2:]\n",
    "        return top_line, bottom_line\n",
    "    else:                                        # two-liner from one character\n",
    "        concat_line = text[:newline] + ' ' + text[newline + 1:]\n",
    "        return concat_line, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I missed you.', 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_line(subs[29].text) # one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I missed you so much.', 'MOLLY: Been one night.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_line(subs[30].text) # two-liner spoken by two characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I mean, he's you know, he's the vice president.\", 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_line(subs[69].text) # two-liner from one character"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
