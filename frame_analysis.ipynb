{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frame_analysis\n",
    "This notebook contains exploration of various computer vision analyses, in individual frames. These are to help with overall *Moviegoer* goals, such as for dialogue attribution, or character identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import face_recognition\n",
    "from scene_cluster_io import *\n",
    "from keras import models\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouth Open or Closed\n",
    "A major goal of the project is dialogue attribution, or determining which character is speaking. This is very easy for humans, of course, but difficult for machines to understand.\n",
    "\n",
    "Usually, the film shows whoever is currently speaking, but sometimes it's more important to show a character listening, and reacting to dialogue. If we can determine if the character onscreen has his or her mouth open, we can reasonably assume that they're the one speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'hobbs_shaw'\n",
    "frame = 766\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)\n",
    "img_path = dialogue_folder + '/' + film + '_frame' + str(frame) + '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the face_recognition library to find a face in an individual movie frame. Then we'll take a closer look at the position of the face landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s) in frame 766\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(img_path)\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print('Found ' + str(len(face_locations)) + ' face(s) in frame ' + str(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(image, face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "face_landmarks = face_landmarks_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the locations of all the face landmarks, we can take a closer look at the character's mouth, specifically at the the locations of the top and bottom lip. Knowing these, we can calculate the overall size of the mouth, and if it's greater than a certain threshold, we declare the mouth is open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lip_height(lip):\n",
    "    for i in [2,3,4]:\n",
    "        sum = 0\n",
    "        distance = math.sqrt( (lip[i][0] - lip[12-i][0])**2 +\n",
    "                              (lip[i][1] - lip[12-i][1])**2   )\n",
    "        sum += distance\n",
    "    return sum / 3\n",
    "\n",
    "\n",
    "def get_mouth_height(top_lip, bottom_lip):\n",
    "    for i in [8,9,10]:\n",
    "        sum = 0\n",
    "        distance = math.sqrt( (top_lip[i][0] - bottom_lip[18-i][0])**2 + \n",
    "                              (top_lip[i][1] - bottom_lip[18-i][1])**2   )\n",
    "        sum += distance\n",
    "    return sum / 3\n",
    "\n",
    "\n",
    "def mouth_open_check(face_landmarks, open_ratio=.8):\n",
    "    top_lip = face_landmarks['top_lip']\n",
    "    bottom_lip = face_landmarks['bottom_lip']\n",
    "    \n",
    "    top_lip_height =    get_lip_height(top_lip)\n",
    "    bottom_lip_height = get_lip_height(bottom_lip)\n",
    "    mouth_height =      get_mouth_height(top_lip, bottom_lip)\n",
    "\n",
    "    if mouth_height > min(top_lip_height, bottom_lip_height) * open_ratio:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouth_open_check(face_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add this to the DataFrame about individual frames, which was originally created as part of the scene clustering process. Below I've manually designated a scene to be analyzed. We cluster all the frames into shots, and then assign unique Shot IDs, as well as predict if they're Medium Close-Up shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8194 images in the folder\n",
      "Selected 57 of those frames\n",
      "Number of clusters: 4\n"
     ]
    }
   ],
   "source": [
    "film = 'hobbs_shaw'\n",
    "frame_choice = list(range(766, 823))\n",
    "threshold = 3000\n",
    "\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)\n",
    "print('There are', len(os.listdir(dialogue_folder)), 'images in the folder')\n",
    "print('Selected', len(frame_choice), 'of those frames')\n",
    "\n",
    "hac_labels = label_clusters(dialogue_folder, frame_choice, film, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = models.load_model('saved_models/tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_values = predict_mcu(dialogue_folder, tuned_model, frame_choice, film)\n",
    "shot_id_list = get_shot_ids(frame_choice, hac_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check if a character has an open mouth in each frame. We run through each frame, appending a 0 or 1 to `mouth_open_list`. This will be zipped into a DataFrame along with our other frame data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found landmarks for 1 face(s) in frame 766\n",
      "Found landmarks for 1 face(s) in frame 767\n",
      "Found landmarks for 0 face(s) in frame 768\n",
      "Found landmarks for 1 face(s) in frame 769\n",
      "Found landmarks for 1 face(s) in frame 770\n",
      "Found landmarks for 1 face(s) in frame 771\n",
      "Found landmarks for 1 face(s) in frame 772\n",
      "Found landmarks for 1 face(s) in frame 773\n",
      "Found landmarks for 0 face(s) in frame 774\n",
      "Found landmarks for 1 face(s) in frame 775\n",
      "Found landmarks for 1 face(s) in frame 776\n",
      "Found landmarks for 1 face(s) in frame 777\n",
      "Found landmarks for 1 face(s) in frame 778\n",
      "Found landmarks for 1 face(s) in frame 779\n",
      "Found landmarks for 1 face(s) in frame 780\n",
      "Found landmarks for 1 face(s) in frame 781\n",
      "Found landmarks for 1 face(s) in frame 782\n",
      "Found landmarks for 0 face(s) in frame 783\n",
      "Found landmarks for 0 face(s) in frame 784\n",
      "Found landmarks for 0 face(s) in frame 785\n",
      "Found landmarks for 1 face(s) in frame 786\n",
      "Found landmarks for 1 face(s) in frame 787\n",
      "Found landmarks for 1 face(s) in frame 788\n",
      "Found landmarks for 0 face(s) in frame 789\n",
      "Found landmarks for 0 face(s) in frame 790\n",
      "Found landmarks for 1 face(s) in frame 791\n",
      "Found landmarks for 1 face(s) in frame 792\n",
      "Found landmarks for 0 face(s) in frame 793\n",
      "Found landmarks for 1 face(s) in frame 794\n",
      "Found landmarks for 1 face(s) in frame 795\n",
      "Found landmarks for 1 face(s) in frame 796\n",
      "Found landmarks for 1 face(s) in frame 797\n",
      "Found landmarks for 1 face(s) in frame 798\n",
      "Found landmarks for 1 face(s) in frame 799\n",
      "Found landmarks for 1 face(s) in frame 800\n",
      "Found landmarks for 1 face(s) in frame 801\n",
      "Found landmarks for 1 face(s) in frame 802\n",
      "Found landmarks for 1 face(s) in frame 803\n",
      "Found landmarks for 1 face(s) in frame 804\n",
      "Found landmarks for 1 face(s) in frame 805\n",
      "Found landmarks for 1 face(s) in frame 806\n",
      "Found landmarks for 1 face(s) in frame 807\n",
      "Found landmarks for 1 face(s) in frame 808\n",
      "Found landmarks for 1 face(s) in frame 809\n",
      "Found landmarks for 0 face(s) in frame 810\n",
      "Found landmarks for 0 face(s) in frame 811\n",
      "Found landmarks for 1 face(s) in frame 812\n",
      "Found landmarks for 1 face(s) in frame 813\n",
      "Found landmarks for 1 face(s) in frame 814\n",
      "Found landmarks for 1 face(s) in frame 815\n",
      "Found landmarks for 0 face(s) in frame 816\n",
      "Found landmarks for 0 face(s) in frame 817\n",
      "Found landmarks for 1 face(s) in frame 818\n",
      "Found landmarks for 1 face(s) in frame 819\n",
      "Found landmarks for 1 face(s) in frame 820\n",
      "Found landmarks for 1 face(s) in frame 821\n",
      "Found landmarks for 1 face(s) in frame 822\n"
     ]
    }
   ],
   "source": [
    "mouth_open_list = []\n",
    "\n",
    "for x in frame_choice:\n",
    "    img_path = dialogue_folder + '/' + film + '_frame' + str(x) + '.jpg'\n",
    "    image = face_recognition.load_image_file(img_path)\n",
    "    face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=1)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image, face_locations)\n",
    "    print('Found landmarks for ' + str(len(face_landmarks_list)) + ' face(s) in frame ' + str(x))\n",
    "\n",
    "    if face_landmarks_list:\n",
    "        face_landmarks = face_landmarks_list[0]\n",
    "        mouth_open_list.append(mouth_open_check(face_landmarks))\n",
    "    else:\n",
    "        mouth_open_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_file</th>\n",
       "      <th>cluster</th>\n",
       "      <th>shot_id</th>\n",
       "      <th>mcu</th>\n",
       "      <th>mouth_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>766</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_file  cluster  shot_id  mcu  mouth_open\n",
       "0         766        3        0    0           1\n",
       "1         767        3        0    1           1\n",
       "2         768        3        0    1           0\n",
       "3         769        3        0    1           1\n",
       "4         770        2        1    1           0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_df = pd.DataFrame(zip(frame_choice, hac_labels, shot_id_list, y_pred_values, mouth_open_list), columns=['frame_file', 'cluster', 'shot_id', 'mcu', 'mouth_open'])\n",
    "scene_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
