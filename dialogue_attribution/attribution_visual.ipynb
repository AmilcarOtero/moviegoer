{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attribution_visual\n",
    "This notebook explores various computer vision analyses using the `face_recogntion` library, in individual frames. These are to help with overall dialogue attribution. With two-character dialogue scenes identified, we need to be able to identify each character and determine which one is speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import face_recognition\n",
    "from scene_cluster_io import *\n",
    "from keras import models\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification\n",
    "Within each frame, we can count the number of faces, and store faces as encodings using the `face_recognition` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'hobbs_shaw'\n",
    "frame = 766\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)\n",
    "img_path = dialogue_folder + '/' + film + '_frame' + str(frame) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s) in frame 766\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(img_path)\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=1)\n",
    "\n",
    "print('Found ' + str(len(face_locations)) + ' face(s) in frame ' + str(frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Identification using clustering\n",
    "Using HAC Clustering, we can turn a list of facial encodings into clusters, each representing a character. We'll have two lists, `faces_found`, which represents the number of faces found per frame, and `encodings_list`, which will contain the facial_encoding for each face.\n",
    "\n",
    "For this stage of the project, we want to only record the \"primary character\" for each frame. Later, this logic will be updated to detect which is the primary character by facial size. The character closest to the foreground, physically the largest in frame, will be the primary character. But for this example, there's only one face per frame.\n",
    "\n",
    "Here's an example from *Hobbs & Shaw*, a two-character scene which I've manually designated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'hobbs_shaw'\n",
    "frame_choice = list(range(766, 823))\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s) in frame 766\n",
      "Found 1 face(s) in frame 767\n",
      "Found 0 face(s) in frame 768\n",
      "Found 1 face(s) in frame 769\n",
      "Found 1 face(s) in frame 770\n",
      "Found 1 face(s) in frame 771\n",
      "Found 1 face(s) in frame 772\n",
      "Found 1 face(s) in frame 773\n",
      "Found 0 face(s) in frame 774\n",
      "Found 1 face(s) in frame 775\n",
      "Found 1 face(s) in frame 776\n",
      "Found 1 face(s) in frame 777\n",
      "Found 1 face(s) in frame 778\n",
      "Found 1 face(s) in frame 779\n",
      "Found 1 face(s) in frame 780\n",
      "Found 1 face(s) in frame 781\n",
      "Found 1 face(s) in frame 782\n",
      "Found 0 face(s) in frame 783\n",
      "Found 0 face(s) in frame 784\n",
      "Found 0 face(s) in frame 785\n",
      "Found 1 face(s) in frame 786\n",
      "Found 1 face(s) in frame 787\n",
      "Found 1 face(s) in frame 788\n",
      "Found 0 face(s) in frame 789\n",
      "Found 0 face(s) in frame 790\n",
      "Found 1 face(s) in frame 791\n",
      "Found 1 face(s) in frame 792\n",
      "Found 0 face(s) in frame 793\n",
      "Found 1 face(s) in frame 794\n",
      "Found 1 face(s) in frame 795\n",
      "Found 1 face(s) in frame 796\n",
      "Found 1 face(s) in frame 797\n",
      "Found 1 face(s) in frame 798\n",
      "Found 1 face(s) in frame 799\n",
      "Found 1 face(s) in frame 800\n",
      "Found 1 face(s) in frame 801\n",
      "Found 1 face(s) in frame 802\n",
      "Found 1 face(s) in frame 803\n",
      "Found 1 face(s) in frame 804\n",
      "Found 1 face(s) in frame 805\n",
      "Found 1 face(s) in frame 806\n",
      "Found 1 face(s) in frame 807\n",
      "Found 1 face(s) in frame 808\n",
      "Found 1 face(s) in frame 809\n",
      "Found 0 face(s) in frame 810\n",
      "Found 0 face(s) in frame 811\n",
      "Found 1 face(s) in frame 812\n",
      "Found 1 face(s) in frame 813\n",
      "Found 1 face(s) in frame 814\n",
      "Found 1 face(s) in frame 815\n",
      "Found 0 face(s) in frame 816\n",
      "Found 0 face(s) in frame 817\n",
      "Found 1 face(s) in frame 818\n",
      "Found 1 face(s) in frame 819\n",
      "Found 1 face(s) in frame 820\n",
      "Found 1 face(s) in frame 821\n",
      "Found 1 face(s) in frame 822\n"
     ]
    }
   ],
   "source": [
    "faces_found = []\n",
    "encodings_list = []\n",
    "\n",
    "for x in frame_choice:\n",
    "    img_path = dialogue_folder + '/' + film + '_frame' + str(x) + '.jpg'\n",
    "    image = face_recognition.load_image_file(img_path)\n",
    "    face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=1)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image, face_locations)\n",
    "\n",
    "    print('Found ' + str(len(face_locations)) + ' face(s) in frame ' + str(x))\n",
    "    frame_encodings_list = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "    if frame_encodings_list:\n",
    "        encoding = frame_encodings_list[0]\n",
    "        encodings_list.append(encoding)\n",
    "        faces_found.append(len(face_locations))\n",
    "        face_landmarks = face_landmarks_list[0]\n",
    "    else:\n",
    "        faces_found.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a list of facial encodings, we can cluster them into characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the list as a NumPy array\n",
    "encodings_list_np = np.array(encodings_list)\n",
    "encodings_list_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2\n",
      "[0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "hac = AgglomerativeClustering(n_clusters = None, distance_threshold = 1).fit(encodings_list_np)\n",
    "hac_labels = hac.labels_\n",
    "print('Number of clusters:', hac.n_clusters_)\n",
    "print(hac_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've found two clusters, each representing one of the characters in the scene. Before we can use it as part of a DataFrame, we need to get the list into the correct \"shape\". Recall that a face wasn't found in every frame. So the `len` of `faces_found` and `encodings_list` aren't the same.\n",
    "\n",
    "While fixing this, it's a good time to assign (arbitrary) names to the characters. Rather than 0 or 1, we'll call them A or B (or C, etc.). This is to avoid confusion around continuous data, and the fact that other clusters will be using 0 and 1 but may not necessarily be correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_character_list = []\n",
    "y = 0\n",
    "for x in faces_found:\n",
    "    if x != 0:\n",
    "        primary_character_list.append(chr(hac_labels[y]+65)) # converts numbers to Unicode characters (A, B, etc.)\n",
    "        y +=1\n",
    "    else:\n",
    "        primary_character_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(faces_found))\n",
    "print(len(primary_character_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at these results later, inserting them into a larger DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouth Open or Closed\n",
    "A major goal of the project is dialogue attribution, or determining which character is speaking. This is very easy for humans, of course, but difficult for machines to understand.\n",
    "\n",
    "Usually, the film shows whoever is currently speaking, but sometimes it's more important to show a character listening, and reacting to dialogue. If we can determine if the character onscreen has his or her mouth open, we can reasonably assume that they're the one speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'hobbs_shaw'\n",
    "frame = 766\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)\n",
    "img_path = dialogue_folder + '/' + film + '_frame' + str(frame) + '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `face_recognition` library to find a face in an individual movie frame. Then we'll take a closer look at the position of the face landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s) in frame 766\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(img_path)\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print('Found ' + str(len(face_locations)) + ' face(s) in frame ' + str(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(image, face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "face_landmarks = face_landmarks_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the locations of all the face landmarks, we can take a closer look at the character's mouth, specifically at the the locations of the top and bottom lip. Knowing these, we can calculate the overall size of the mouth, and if it's greater than a certain threshold, we declare the mouth is open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lip_height(lip):\n",
    "    for i in [2 ,3 ,4]:\n",
    "        sum = 0\n",
    "        distance = math.sqrt((lip[i][0] - lip[12-i][0])**2 + (lip[i][1] - lip[12-i][1])**2)\n",
    "        sum += distance\n",
    "    return sum / 3\n",
    "\n",
    "\n",
    "def get_mouth_height(top_lip, bottom_lip):\n",
    "    for i in [8 ,9 ,10]:\n",
    "        sum = 0\n",
    "        distance = math.sqrt((top_lip[i][0] - bottom_lip[18-i][0])**2 + (top_lip[i][1] - bottom_lip[18-i][1])**2)\n",
    "        sum += distance\n",
    "    return sum / 3\n",
    "\n",
    "\n",
    "def mouth_open_check(face_landmarks, open_ratio=.8):\n",
    "    top_lip = face_landmarks['top_lip']\n",
    "    bottom_lip = face_landmarks['bottom_lip']\n",
    "\n",
    "    top_lip_height = get_lip_height(top_lip)\n",
    "    bottom_lip_height = get_lip_height(bottom_lip)\n",
    "    mouth_height = get_mouth_height(top_lip, bottom_lip)\n",
    "\n",
    "    if mouth_height > min(top_lip_height, bottom_lip_height) * open_ratio:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouth_open_check(face_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add this to the DataFrame about individual frames, which was originally created as part of the scene clustering process. Below I've manually designated a scene to be analyzed. We cluster all the frames into shots, and then assign unique Shot IDs, as well as predict if they're Medium Close-Up shots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouth Open/Closed Analysis on Multiple Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8194 images in the folder\n",
      "Selected 57 of those frames\n",
      "Number of clusters: 4\n"
     ]
    }
   ],
   "source": [
    "film = 'hobbs_shaw'\n",
    "frame_choice = list(range(766, 823))\n",
    "threshold = 3000\n",
    "\n",
    "dialogue_folder = os.path.join('dialogue_frames', film)\n",
    "print('There are', len(os.listdir(dialogue_folder)), 'images in the folder')\n",
    "print('Selected', len(frame_choice), 'of those frames')\n",
    "\n",
    "hac_labels = label_clusters(dialogue_folder, frame_choice, film, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = models.load_model('saved_models/tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_values = predict_mcu(dialogue_folder, tuned_model, frame_choice, film)\n",
    "shot_id_list = get_shot_ids(frame_choice, hac_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check if a character has an open mouth in each frame. We run through each frame, appending a 0 or 1 to `mouth_open_list`. This will be zipped into a DataFrame along with our other frame data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found landmarks for 1 face(s) in frame 766\n",
      "Found landmarks for 1 face(s) in frame 767\n",
      "Found landmarks for 0 face(s) in frame 768\n",
      "Found landmarks for 1 face(s) in frame 769\n",
      "Found landmarks for 1 face(s) in frame 770\n",
      "Found landmarks for 1 face(s) in frame 771\n",
      "Found landmarks for 1 face(s) in frame 772\n",
      "Found landmarks for 1 face(s) in frame 773\n",
      "Found landmarks for 0 face(s) in frame 774\n",
      "Found landmarks for 1 face(s) in frame 775\n",
      "Found landmarks for 1 face(s) in frame 776\n",
      "Found landmarks for 1 face(s) in frame 777\n",
      "Found landmarks for 1 face(s) in frame 778\n",
      "Found landmarks for 1 face(s) in frame 779\n",
      "Found landmarks for 1 face(s) in frame 780\n",
      "Found landmarks for 1 face(s) in frame 781\n",
      "Found landmarks for 1 face(s) in frame 782\n",
      "Found landmarks for 0 face(s) in frame 783\n",
      "Found landmarks for 0 face(s) in frame 784\n",
      "Found landmarks for 0 face(s) in frame 785\n",
      "Found landmarks for 1 face(s) in frame 786\n",
      "Found landmarks for 1 face(s) in frame 787\n",
      "Found landmarks for 1 face(s) in frame 788\n",
      "Found landmarks for 0 face(s) in frame 789\n",
      "Found landmarks for 0 face(s) in frame 790\n",
      "Found landmarks for 1 face(s) in frame 791\n",
      "Found landmarks for 1 face(s) in frame 792\n",
      "Found landmarks for 0 face(s) in frame 793\n",
      "Found landmarks for 1 face(s) in frame 794\n",
      "Found landmarks for 1 face(s) in frame 795\n",
      "Found landmarks for 1 face(s) in frame 796\n",
      "Found landmarks for 1 face(s) in frame 797\n",
      "Found landmarks for 1 face(s) in frame 798\n",
      "Found landmarks for 1 face(s) in frame 799\n",
      "Found landmarks for 1 face(s) in frame 800\n",
      "Found landmarks for 1 face(s) in frame 801\n",
      "Found landmarks for 1 face(s) in frame 802\n",
      "Found landmarks for 1 face(s) in frame 803\n",
      "Found landmarks for 1 face(s) in frame 804\n",
      "Found landmarks for 1 face(s) in frame 805\n",
      "Found landmarks for 1 face(s) in frame 806\n",
      "Found landmarks for 1 face(s) in frame 807\n",
      "Found landmarks for 1 face(s) in frame 808\n",
      "Found landmarks for 1 face(s) in frame 809\n",
      "Found landmarks for 0 face(s) in frame 810\n",
      "Found landmarks for 0 face(s) in frame 811\n",
      "Found landmarks for 1 face(s) in frame 812\n",
      "Found landmarks for 1 face(s) in frame 813\n",
      "Found landmarks for 1 face(s) in frame 814\n",
      "Found landmarks for 1 face(s) in frame 815\n",
      "Found landmarks for 0 face(s) in frame 816\n",
      "Found landmarks for 0 face(s) in frame 817\n",
      "Found landmarks for 1 face(s) in frame 818\n",
      "Found landmarks for 1 face(s) in frame 819\n",
      "Found landmarks for 1 face(s) in frame 820\n",
      "Found landmarks for 1 face(s) in frame 821\n",
      "Found landmarks for 1 face(s) in frame 822\n"
     ]
    }
   ],
   "source": [
    "mouth_open_list = []\n",
    "\n",
    "for x in frame_choice:\n",
    "    img_path = dialogue_folder + '/' + film + '_frame' + str(x) + '.jpg'\n",
    "    image = face_recognition.load_image_file(img_path)\n",
    "    face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=1)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image, face_locations)\n",
    "    print('Found landmarks for ' + str(len(face_landmarks_list)) + ' face(s) in frame ' + str(x))\n",
    "\n",
    "    if face_landmarks_list:\n",
    "        face_landmarks = face_landmarks_list[0]\n",
    "        mouth_open_list.append(mouth_open_check(face_landmarks))\n",
    "    else:\n",
    "        mouth_open_list.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame DataFrame\n",
    "We can compile the number of faces found, the primary character, and whether that character's mouth is open into a DataFrame along with our scene clustering information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_file</th>\n",
       "      <th>cluster</th>\n",
       "      <th>shot_id</th>\n",
       "      <th>mcu</th>\n",
       "      <th>faces_found</th>\n",
       "      <th>primary_character</th>\n",
       "      <th>mouth_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>766</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>771</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>772</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>773</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_file  cluster  shot_id  mcu  faces_found primary_character  \\\n",
       "0         766        3        0    0            1                 A   \n",
       "1         767        3        0    1            1                 A   \n",
       "2         768        3        0    1            0                 0   \n",
       "3         769        3        0    1            1                 A   \n",
       "4         770        2        1    1            1                 B   \n",
       "5         771        2        1    1            1                 B   \n",
       "6         772        2        1    1            1                 B   \n",
       "7         773        3        2    1            1                 A   \n",
       "\n",
       "   mouth_open  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  \n",
       "5           1  \n",
       "6           0  \n",
       "7           1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_df = pd.DataFrame(zip(frame_choice, hac_labels, shot_id_list, y_pred_values, faces_found, primary_character_list, mouth_open_list), columns=['frame_file', 'cluster', 'shot_id', 'mcu', 'faces_found', 'primary_character', 'mouth_open'])\n",
    "scene_df.head(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
