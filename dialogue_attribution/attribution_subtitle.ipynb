{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attribution_subtitles\n",
    "This notebook explores the use of the `pysrt` library to analyze subtitle files. These .srt files are simply text files with specific formatting that allows them to be read by media players. The goal is to be able to assemble a scene's entire conversation and attribute individual lines to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pysrt\n",
    "import pyAudioAnalysis.audioSegmentation\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Subtitles\n",
    "\n",
    ".srt subtitle files have a very specific format. Each entry has an index number, a start and end time (both in HH:MM:SS,mmm format), and either one or two lines of dialogue. This formatting makes it very easy for the `pysrt` library to convert an entire .srt file into a list of subtitle objects, `SubRipItem`.\n",
    "\n",
    "We'll look at an example from *Hobbs and Shaw*. Below is an example of formatting from an .srt file.\n",
    "\n",
    "266\n",
    "\n",
    "00:12:49,102 --> 00:12:51,103\n",
    "\n",
    "No wonder we left\n",
    "\n",
    "the family business.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/hobbs_shaw.srt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .srt file index starts at 1, while the `subs` list starts at 0. As a quick way to align the two, we simply duplicate the first subtitle object (`SubRipItem`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle files (.srt) are explicitly numbered, and start at 1\n",
    "subs.insert(0, subs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Subtitle Objects\n",
    "`SubRipItem` objects contain the `text` attribute, which is the one or two lines of dialogue. They also contain `start` and `end`, which can be broken down into hours, minutes, seconds, and milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(\"Time in a Bottle\"\\nby Yungblud playing)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want her on the run\n",
      "with no place to turn.\n"
     ]
    }
   ],
   "source": [
    "print(subs[62].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "32\n",
      "522\n"
     ]
    }
   ],
   "source": [
    "print(subs[62].start.hours)\n",
    "print(subs[62].start.minutes)\n",
    "print(subs[62].start.seconds)\n",
    "print(subs[62].start.milliseconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "One of the challenges is working with separate timestamp systems. The subtitle file (and the extracted subtitle list) starts from the beginning of the film, while (for this exploratory example) the audio file starts at a manually-designated start time. Later, we'll have the issue of using the frame number to identify a time.\n",
    "\n",
    "The subtitles have three methods we can use for time:\n",
    "\n",
    "`.slice()` returns all subtitles occurring in a range before/after start/end times\n",
    "\n",
    "`.at()` returns a single subtitle occurring at a specific time\n",
    "\n",
    "`.to_time()` returns a `datetime.time` object containing hours, minutes, seconds, and milliseconds, that can be used universally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = subs.slice(starts_after={'minutes': 12, 'seconds': 47, 'milliseconds': 400}, ends_before={'minutes': 12, 'seconds': 49, 'milliseconds': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = subs.at(minutes=12, seconds=47, milliseconds=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pysrt.srtitem.SubRipItem object at 0x7f699bd3bdd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_obj = subs[271].start.to_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(0, 13, 0, 613000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, we'll eventually be working with frames, the visual images generated once per second. The frames' filenames will contain a frame number, which corresponds cleanly to the number of seconds elapsed. So `hobbs_shaw_frame48.jpg` shows what happens 48 seconds into the film.\n",
    "\n",
    "The below function will be able to convert that number into a `datetime.time` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_time(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hours = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    \n",
    "    timestamp = datetime.time(hours, minutes, seconds)\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitles Onscreen Flag\n",
    "To assist with dialogue attribution, we can create a flag to identify if there are subtitle onscreen during a given frame. This will require converting a frame number (in its filename) to a subtitle timestamp. This gives us a HH:MM:SS time object, but remember that subtitles also work with milliseconds. For each time, we should check if there's a subtitle at HH:MM:SS,000 or at HH:MM:SS,999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtitle found\n"
     ]
    }
   ],
   "source": [
    "if subs.at(datetime.time(0, 12, 47, 0)) or subs.at(datetime.time(0, 12, 47, 999)):\n",
    "    print('subtitle found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = frame_to_time(766)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtitle found\n"
     ]
    }
   ],
   "source": [
    "if subs.at(first_frame) or subs.at(first_frame.replace(microsecond=999000)):\n",
    "    print('subtitle found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a specific type of subtitles that we don't want to trigger the subtitle_onscreen flag: parentheticals. These are used to communicate scene audio, like in-scene sound effects, or non-dialogue sounds made by characters, like laughter. These are written in subtitles as parentheticals, and we can exclude these from our subtitle_onscreen check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(laughs)\n"
     ]
    }
   ],
   "source": [
    "laugh_frame = frame_to_time(766)\n",
    "print(subs.at(laugh_frame).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(music playing quietly\n",
      "over speakers)\n"
     ]
    }
   ],
   "source": [
    "scene_music_frame = frame_to_time(824)\n",
    "print(subs.at(scene_music_frame).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parenthetical subtitle: no spoken dialogue\n"
     ]
    }
   ],
   "source": [
    "if subs.at(laugh_frame).text[0] == '(' and subs.at(laugh_frame).text[-1] == ')':\n",
    "    print('Parenthetical subtitle: no spoken dialogue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtitle with spoken dialogue\n"
     ]
    }
   ],
   "source": [
    "# inverse of above\n",
    "if subs.at(laugh_frame).text[0] != '(' or subs.at(laugh_frame).text[-1] != ')':\n",
    "    pass\n",
    "else:\n",
    "    print('Subtitle with spoken dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block will iterate through each frame and see if there's a subtitle onscreen at the beginning or end of the frame's duration. If a subtitle is found, it checks if it's a parenthetical subtitle. It creates a size-58 list that we'll use later in the frame DataFrame for dialogue attribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_choice = list(range(766, 824))\n",
    "\n",
    "subtitle_onscreen = []\n",
    "for frame in frame_choice:\n",
    "    time = frame_to_time(frame)\n",
    "    \n",
    "    if subs.at(time) and (subs.at(time).text[0] != '(' or subs.at(time).text[-1] != ')'):\n",
    "        subtitle_onscreen.append(1)\n",
    "    elif subs.at(time.replace(microsecond=999000)) and (subs.at(time.replace(microsecond=999000)).text[0] != '(' or subs.at(time.replace(microsecond=999000)).text[-1] != ')'):\n",
    "        subtitle_onscreen.append(1)\n",
    "    else:\n",
    "        subtitle_onscreen.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subtitle_onscreen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle_onscreen[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
