{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate various parameter tunings' impact on baseline model performance. Generally, only a single parameter will be tuned during each test; however, certain parameters will require multiple tunings, such as a 6x6 CNN layer requiring a certain input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import metric_functions as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting Pillow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/50/8e78e6f62ffa50d6ca95c281d5a2819bef66d023ac1b723e253de5bda9c5/Pillow-7.1.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-7.1.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.1)\n",
      "Collecting pyyaml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Building wheels for collected packages: pyyaml\n",
      "\u001b[33m  WARNING: Building wheel for pyyaml failed: [Errno 13] Permission denied: '/.cache'\u001b[0m\n",
      "Failed to build pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "    Running setup.py install for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed keras-2.3.1 pyyaml-5.3.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/cd/af7469eb9d2b2ba428206273585f0272b6094ae915aed0b1ca99eace56df/scikit_learn-0.23.0-cp36-cp36m-manylinux1_x86_64.whl (7.3MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl (298kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 696kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/db/09/cab2f398e28e9f183714afde872b2ce23629f5833e467b151f18e1e08908/threadpoolctl-2.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "\u001b[33m  WARNING: Building wheel for sklearn failed: [Errno 13] Permission denied: '/.cache'\u001b[0m\n",
      "Failed to build sklearn\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n",
      "    Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed joblib-0.15.1 scikit-learn-0.23.0 sklearn-0.0 threadpoolctl-2.0.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Create Data <a id='data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = 'mixed_frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5214 images in the Train set\n",
      "There are 1852 images in the Test set\n",
      "\n",
      "\n",
      "There are 1916 MCU images in the train set\n",
      "There are 3298 non-MCU images in the train set\n",
      "There are 478 MCU images in the test set\n",
      "There are 1374 non-MCU images in the test set\n"
     ]
    }
   ],
   "source": [
    "train_folder = os.path.join('mcu_data', working_directory, 'train')\n",
    "train_mcu = os.path.join(train_folder, 'mcu')\n",
    "train_non = os.path.join(train_folder, 'non_mcu')\n",
    "\n",
    "test_folder = os.path.join('mcu_data', working_directory, 'test')\n",
    "test_mcu = os.path.join(test_folder, 'mcu')\n",
    "test_non = os.path.join(test_folder, 'non_mcu')\n",
    "\n",
    "print('There are', len(os.listdir(train_mcu)) + len(os.listdir(train_non)), 'images in the Train set')\n",
    "print('There are', len(os.listdir(test_mcu)) + len(os.listdir(test_non)), 'images in the Test set')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('There are', len(os.listdir(train_mcu)), 'MCU images in the train set')\n",
    "print('There are', len(os.listdir(train_non)), 'non-MCU images in the train set')\n",
    "print('There are', len(os.listdir(test_mcu)), 'MCU images in the test set')\n",
    "print('There are', len(os.listdir(test_non)), 'non-MCU images in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input data with image size of 185 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3031 images belonging to 2 classes.\n",
      "Found 756 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size = (185, 100),\n",
    "    batch_size = 4148,\n",
    "    color_mode = 'grayscale',\n",
    "    subset = 'training')\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size = (185, 100),\n",
    "    batch_size = 4148,\n",
    "    color_mode = 'grayscale',\n",
    "    subset = 'validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1718 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_folder, target_size=(185, 100), color_mode = 'grayscale', batch_size = 1781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (3031, 185, 100, 1)\n",
      "train_labels shape: (3031, 2)\n",
      "val_images shape: (756, 185, 100, 1)\n",
      "val_labels shape: (756, 2)\n",
      "test_images shape: (1718, 185, 100, 1)\n",
      "test_labels shape: (1718, 2)\n"
     ]
    }
   ],
   "source": [
    "class_labels = ['Non-MCU', 'MCU']\n",
    "train_images, train_labels = next(train_generator)\n",
    "val_images, val_labels = next(val_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "train_y = np.reshape(train_labels[:,0], (3031,1))\n",
    "val_y = np.reshape(val_labels[:,0], (756,1))\n",
    "test_y = np.reshape(test_labels[:,0], (1718,1))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input data with image size of 128 x 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4172 images belonging to 2 classes.\n",
      "Found 1042 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size = (128, 128),\n",
    "    batch_size = 4172,\n",
    "    color_mode = 'grayscale',\n",
    "    subset = 'training')\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size = (128, 128),\n",
    "    batch_size = 1042,\n",
    "    color_mode = 'grayscale',\n",
    "    subset = 'validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1852 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_folder, target_size=(128, 128), color_mode = 'grayscale', batch_size = 1852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (4172, 128, 128, 1)\n",
      "train_labels shape: (4172, 2)\n",
      "val_images shape: (1042, 128, 128, 1)\n",
      "val_labels shape: (1042, 2)\n",
      "test_images shape: (1852, 128, 128, 1)\n",
      "test_labels shape: (1852, 2)\n"
     ]
    }
   ],
   "source": [
    "class_labels = ['Non-MCU', 'MCU']\n",
    "train_images, train_labels = next(train_generator)\n",
    "val_images, val_labels = next(val_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "train_y = np.reshape(train_labels[:,0], (4172,1))\n",
    "val_y = np.reshape(val_labels[:,0], (1042,1))\n",
    "test_y = np.reshape(test_labels[:,0], (1852,1))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning <a id='Tuning'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
