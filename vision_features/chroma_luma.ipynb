{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chroma_luma\n",
    "This notebook explores the various chroma (color) and luma (brightness) features that can be extracted from individual frames. We'll be making extensive use of the `OpenCV` computer vision library. Functionality demonstrated here will be replicated in a functions file, and then used to populate the frame-level DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'parasite'\n",
    "frame = 933\n",
    "frame_folder = os.path.join('../frame_per_second', film)\n",
    "img_path = frame_folder + '/' + film + '_frame' + str(frame) + '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an image\n",
    "We can load the image and get its width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358, 854, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this frame is 854 (width) x 358 (height) pixels and has a BGR value\n",
    "image = cv2.imread(img_path)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a (width, height) coordinate and get the BGR value, consisting of three color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53, 74, 71], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[10][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blank Frames\n",
    "The easiest frame to spot is the blank frame, with either all black or all white pixels. These could be used to identify scene transitions, such as when a scene ends with a dip-to-black or dip-to-white, transitioning to blank frames before the next scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-black frames\n",
    "We can calculate the mean luminosity of the image by calculating the average of every BGR value for every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'parasite'\n",
    "frame = 22\n",
    "frame_folder = os.path.join('../frame_per_second', film)\n",
    "img_path = frame_folder + '/' + film + '_frame' + str(frame) + '.jpg'\n",
    "image = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every pixel in this frame has a BGR value of (0, 0, 0)\n",
    "image.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black frame detected\n"
     ]
    }
   ],
   "source": [
    "if image.mean() < 3: # threshold of 3, to be safe\n",
    "    print('black frame detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-white frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if image.mean() > 252:\n",
    "    print('white frame detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luma\n",
    "Measurements relating to luma.\n",
    "### Mean brightness\n",
    "We can take the brightness of the frame by calculating the average brightness of each pixel. But because each pixel is a color BGR element, we must first convert the image to grayscale, because brightness doesn't map linearly to BGR values. After converting each pixels' three BGR values to a single grayscale value, we can take the mean of the pixels' grayscale values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'booksmart'\n",
    "frame = 4102\n",
    "frame_folder = os.path.join('../frame_per_second', film)\n",
    "img_path = frame_folder + '/' + film + '_frame' + str(frame) + '.jpg'\n",
    "image = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.32336262926611"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is NOT the proper way to calculate brightness\n",
    "image.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.82475067757808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this conversion to grayscale is necessary\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum brightness\n",
    "Although black values always sit at the end of the spectrum (0, 0, 0), white values in H.264-compressed videos rarely approach the pure white point of (255, 255, 255) because of gamma correction, a bandwidth-saving technique. On a display, the human eye doesn't need to see pure white to interpret pure white. Brightness is a power-scale, not a linear-scale, and so gamma correction can be used to reduce the amount of data used to convey white.\n",
    "\n",
    "Below, we can search for the frame's brightest pixel. We may use this to scale white values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.33333333333334\n",
      "[221 211 193]\n",
      "(4, 412)\n"
     ]
    }
   ],
   "source": [
    "brightest_mean = 0\n",
    "brightest_pixel = 0\n",
    "brightest_coordinate = 0\n",
    "x = 0\n",
    "\n",
    "\n",
    "for a in image:\n",
    "    y = 0\n",
    "    for b in a:\n",
    "        if b.mean() > brightest_mean:\n",
    "            brightest_mean = b.mean()\n",
    "            brightest_pixel = b\n",
    "            brightest_coordinate = (x, y)\n",
    "        y += 1\n",
    "    x += 1\n",
    "print(brightest_mean)\n",
    "print(brightest_pixel)\n",
    "print(brightest_coordinate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
